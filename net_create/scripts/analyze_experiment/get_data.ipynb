{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6e9f8c-bf14-48df-b957-33b269c62658",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c145bf0-25b1-4b74-9c7a-afd45e516c72",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../secrets/google_creds.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9de3a8835851>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mkey_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"../../secrets/google_creds.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m credentials = service_account.Credentials.from_service_account_file(key_path,\n\u001b[0m\u001b[1;32m      8\u001b[0m                                                                     scopes=[\n\u001b[1;32m      9\u001b[0m                                                                         \"https://www.googleapis.com/auth/cloud-platform\"], )\n",
      "\u001b[0;32m~/misinformation_sim/lib/python3.8/site-packages/google/oauth2/service_account.py\u001b[0m in \u001b[0;36mfrom_service_account_file\u001b[0;34m(cls, filename, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mcredentials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \"\"\"\n\u001b[0;32m--> 256\u001b[0;31m         info, signer = _service_account_info.from_filename(\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"client_email\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token_uri\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         )\n",
      "\u001b[0;32m~/misinformation_sim/lib/python3.8/site-packages/google/auth/_service_account_info.py\u001b[0m in \u001b[0;36mfrom_filename\u001b[0;34m(filename, require, use_rsa_signer)\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0minfo\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ma\u001b[0m \u001b[0msigner\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequire\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_rsa_signer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_rsa_signer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../secrets/google_creds.json'"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "key_path = f\"../../secrets/google_creds.json\"\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path,\n",
    "                                                                    scopes=[\n",
    "                                                                        \"https://www.googleapis.com/auth/cloud-platform\"], )\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "query = \"\"\"SELECT * FROM\n",
    "`net_expr.trials` AS t\n",
    "INNER JOIN `net_expr.person` as p\n",
    "ON t.participant_id = p.participant_id\n",
    "WHERE \n",
    "p.is_test is FALSE AND p.participant_id != 'seed' \n",
    "\"\"\"\n",
    "query_job = client.query(query)\n",
    "df = query_job.to_dataframe()\n",
    "\n",
    "# Two cases where a test response (response_text == \"Test\") was not flagged --> drop, note in paper\n",
    "er_ids = ['dbe96241-4d64-4ae6-bb6d-15e5e45b0760', 'e6fdd18f-de53-4159-965a-656aa75ba88d']\n",
    "df = df.query(\"response_id not in @er_ids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbfca49-3eea-48b1-946d-1a23ae20c85e",
   "metadata": {},
   "source": [
    "## Data Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd4d7e-53c4-4d3b-971b-402cd52bfe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_rid_unique():\n",
    "    print(\"TEST: Does every response id occur only once?\")\n",
    "    unique_rds = len(df['response_id'].unique())\n",
    "    all_rids = len(df['response_id'].tolist())\n",
    "    if all_rids == unique_rds:\n",
    "        print(\"YES: Every response id only occurs once\")\n",
    "    else:\n",
    "        print(\"NO: Some response ids occur twice\")\n",
    "    \n",
    "    \n",
    "def verify_no_response_blank():\n",
    "    print(\"TEST: Is it the case that all response texts have some words\")\n",
    "    blanks = len([x for x in df['response_id'].tolist() if x is None])\n",
    "    if blanks == 0:\n",
    "        print(\"YES: All responses have some words\")\n",
    "    else:\n",
    "        print(\"NO: Some responses don't have words\")\n",
    "    \n",
    "        \n",
    "verify_rid_unique()\n",
    "print()\n",
    "verify_no_response_blank()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a641a3c-b10b-4b67-b2f3-a59e9e5efd47",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c54bf98-6046-42cc-880a-0400f9490542",
   "metadata": {},
   "source": [
    "## Clean source column\n",
    "\n",
    "We tracked where traffic came from by appending different things to the request arguments for the experiment site. E.g: If posting the experiment on Facebook we would make the URL `experiment.com?from=facebook` so then `request_args` would be equal to `from=facebook`. But in some cases, no `request args` are available. This happens if somehow the request_args are stripped. There should be very few cases of this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ebf96d-c8ff-4153-8dd9-d3f102f3cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_other_source():\n",
    "    print(\"TEST: Does every source marked as OTHER have no request args?\")\n",
    "    other_request_args = df.query(\"source=='other'\")['request_args'].tolist()\n",
    "    len_other = len(other_request_args)\n",
    "    len_other_no_args = len([x for x in other_request_args if x == 'None'])\n",
    "    if len_other == len_other_no_args:\n",
    "        print(\"YES: For every source marked as `other`, we marked it as `other` because it does not have request args\")\n",
    "    else:\n",
    "        print(\"NO: We missed categorizing some sources\")\n",
    "    \n",
    "    \n",
    "\n",
    "def categorize_request_args(request_args):\n",
    "    request_args = request_args.lower()\n",
    "    if 'facebook' in request_args:\n",
    "        return 'facebook'\n",
    "    elif 'chatgpt' in request_args:\n",
    "        return 'r/chatgpt'\n",
    "    elif 'sample' in request_args:\n",
    "        return 'r/samplesize'\n",
    "    elif 'writing' in request_args:\n",
    "        return 'r/writing'\n",
    "    elif 'internet' in request_args:\n",
    "        return 'r/InternetIsBeautiful'\n",
    "    elif 'creative' in request_args:\n",
    "        return 'Creative Mornings newsletter'\n",
    "    elif 'poetry' in request_args:\n",
    "        return 'r/poetry'\n",
    "    elif 'results' in request_args or 'share' in request_args:\n",
    "        return 'share'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "df['source'] = df['request_args'].apply(categorize_request_args)\n",
    "verify_other_source()\n",
    "\n",
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566eaefb-e82f-473b-92d7-de76941e9e80",
   "metadata": {},
   "source": [
    "## Clean Age Columns\n",
    "Participants entered their age, which was an int that had to be over 18. But let's make sure nobody entered anything weird -- and by weird we will look at responses over 70 years old. From inspecting the data, it appears that responses above 74 are troll responses -- relabel as NA and report in paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2debfeeb-fcff-4b91-8492-501391814f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = df.drop_duplicates(subset=['participant_id'])\n",
    "dfp['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd50dd-75b9-4065-ae33-d628531c81d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "over_seven = dfp[dfp['age']>=70]\n",
    "over_seven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab40856-c4f2-4c68-bb24-1308d209c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfp[dfp['age']>74][['participant_id', 'age']].to_latex(caption=\"Users whose age we replaced with missing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791eeca7-b990-43a6-b1e2-5015d7012000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_age(x):\n",
    "    if pd.isnull(x):  # Check for NaN values\n",
    "        return x\n",
    "    elif x <= 74:\n",
    "        return int(x)\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "df['age'] = df['age'].apply(lambda x: fix_age(x))\n",
    "df['age'] = df['age'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9252230c-89a3-4ff5-b64d-e60c1e7ba282",
   "metadata": {},
   "source": [
    "# Clean columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ad9bdb-7a3d-4af2-bdb1-21825f3e8454",
   "metadata": {},
   "source": [
    "## Drop unused columns\n",
    "\n",
    "Note `is_troll` was not used; the relevant column is `is_profane`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56c4988-cc51-4148-818d-b635939d9930",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823c0b0a-7949-4584-8c58-463ace7ef5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\"is_prolific\", \"is_prolific_1\", \"prolific_id\", \"is_test_1\", \"is_troll\", \"dt\", 'participant_id_1']\n",
    "for x in to_drop:\n",
    "    try:\n",
    "        df = df.drop(columns = [x], axis=0)\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90222eda-36df-4018-b351-cc486a07b8b7",
   "metadata": {},
   "source": [
    "## Fix column types and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec03417-e256-4f3e-b5c5-7163c8867dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['creativity_human'] = df['creativity_human'].astype('Int64')\n",
    "df['creativity_ai'] = pd.to_numeric(df['creativity_ai'], errors='coerce').astype('Int64')\n",
    "df = df.rename(columns={'world': 'response_chain'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b69302-4c4e-4cf0-81a0-c9984f804216",
   "metadata": {},
   "source": [
    "# Add trial_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef3be2-fc4d-41cc-ac7f-b42abb818248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['response_date'] = pd.to_datetime(df['response_date'])  # ensure response_date is datetime\n",
    "df['trial_no'] = df.groupby(['response_chain', 'condition', 'item'])['response_date'].rank(method='first').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cc761c-fcdb-4e72-bd01-a7a2e1b51482",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f88c4ce-efc6-48f6-a10a-a6e39a5820de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../data/experiment_data/data_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c24c0-50f5-4bb0-ba0c-4819c1b5202e",
   "metadata": {},
   "source": [
    "# Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2af55c-8dec-432e-a65e-702c553edef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "def make_aesthetic(hex_color_list=None):\n",
    "    \"\"\"Make Seaborn look clean\"\"\"\n",
    "    sns.set(style='white', context='poster', font_scale=0.8)\n",
    "    if not hex_color_list:\n",
    "        hex_color_list = [\n",
    "        \"#826AED\", # Medium slate blue\n",
    "        \"#00A896\", # Persian green\n",
    "        \"#D41876\", # Telemagenta\n",
    "        \"#89DAFF\", # Pale azure\n",
    "        \"#F7B2AD\", # Melon\n",
    "        \"#342E37\", # Dark grayish-purple\n",
    "        \"#7DCD85\", # Emerald\n",
    "        \"#E87461\", # Medium-bright orange\n",
    "        \"#E3B505\", # Saffron\n",
    "        \"#2C3531\", # Dark charcoal gray with a green undertone\n",
    "        \"#D4B2D8\", # Pink lavender\n",
    "        \"#7E6551\", # Coyote\n",
    "        \"#F45B69\", # Vibrant pinkish-red\n",
    "        \"#020887\", # Phthalo Blue\n",
    "        \"#F18805\"  # Tangerine\n",
    "        ]\n",
    "    sns.set_palette(sns.color_palette(hex_color_list))\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rcParams['axes.spines.right'] = False\n",
    "    plt.rcParams['axes.spines.top'] = False\n",
    "    plt.rcParams['axes.titlelocation'] = 'left'\n",
    "    plt.rcParams['axes.titleweight'] = 'bold'\n",
    "    plt.rcParams['axes.grid'] = True\n",
    "    plt.rcParams['grid.linestyle'] = '--'\n",
    "    plt.rcParams['grid.alpha'] = 0.5\n",
    "    plt.rcParams['axes.facecolor'] = 'white'\n",
    "    plt.rcParams['legend.frameon'] = True\n",
    "    plt.rcParams['legend.framealpha'] = 0.8\n",
    "    plt.rcParams['legend.facecolor'] = 'white'\n",
    "    plt.rcParams['savefig.transparent'] = True\n",
    "    plt.rcParams['savefig.bbox'] = 'tight'\n",
    "    plt.rcParams['savefig.pad_inches'] = 0.1\n",
    "    plt.rcParams['figure.autolayout'] = True\n",
    "make_aesthetic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b03449-0794-44ab-8b91-57642fc02a31",
   "metadata": {},
   "source": [
    "### Meta Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef12d38b-3f4e-43b3-a156-823d02b8cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(index=[\"Value\"])\n",
    "df_new['Unique Countries'] = [int(len(df['country'].unique()))]\n",
    "df_new['Total Responses'] = [int(len(df))]\n",
    "df_new['Unique Participants'] = [df['participant_id'].nunique()]\n",
    "df_new['Avg Responses/Participant'] = df_new['Total Responses'] / df_new['Unique Participants']\n",
    "df_new['Avg Duration/Response'] = [df['duration'].mean()]\n",
    "\n",
    "# Round the averages to two decimal places\n",
    "df_new['Avg Responses/Participant'] = df_new['Avg Responses/Participant'].round(2)\n",
    "df_new['Avg Duration/Response'] = df_new['Avg Duration/Response'].round(2)\n",
    "\n",
    "# Print as LaTeX table\n",
    "latex_table = df_new.T.to_latex(index=True, caption=\"Summary Statistics of Experiment\", label=\"overall_stats\")\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab3f133-bc92-4722-9a5a-047fae9b6c75",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6f3d6a-63f1-47ec-92ed-b61a28bd59a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "participants = df.groupby('source')['participant_id'].nunique()\n",
    "percentage_participants = (participants / df['participant_id'].nunique()) * 100\n",
    "trials = df['source'].value_counts()\n",
    "percentage_trials = (trials / df.shape[0]) * 100\n",
    "result = pd.DataFrame({\n",
    "    'Participants': participants,\n",
    "    'Percentage of Participants': percentage_participants,\n",
    "    'Trials': trials,\n",
    "    'Percentage of Trials': percentage_trials,\n",
    "})\n",
    "\n",
    "result = result.sort_values('Participants', ascending=False)\n",
    "result['Participants (N, % of total)'] = result['Participants'].astype(str) + ' (' + result['Percentage of Participants'].round(1).astype(str) + '%)'\n",
    "result['Trials (N, % of total)'] = result['Trials'].astype(str) + ' (' + result['Percentage of Trials'].round(1).astype(str) + '%)'\n",
    "result = result.drop(columns=['Participants', 'Percentage of Participants', 'Trials', 'Percentage of Trials'])\n",
    "latex_table = result.to_latex(caption=\"Sources of participants and trials\", label=\"sources\")\n",
    "\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f0344d-9b9b-4d39-882b-2fadcf856cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class DescriptiveStats:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def generate_categorical_string(self, column, decimal_places):\n",
    "        percentages = self.df[column].value_counts(normalize=True, dropna=True) * 100\n",
    "        percentage_nan = self.df[column].isna().mean() * 100\n",
    "        percentage_string = \", \".join([f\"{percentage:.{decimal_places}f}\\% {index}\" for index, percentage in percentages.items()])\n",
    "        percentage_string += f\". {percentage_nan:.{decimal_places}f}% of responses were missing.\"\n",
    "        return f\"Of the non-missing values, the sample was {percentage_string}\"\n",
    "\n",
    "    def print_latex_table_categorical(self, column, caption=None, label=None, decimal_places=2):\n",
    "        value_counts = self.df[column].value_counts(dropna=False)\n",
    "        value_counts_percentages = self.df[column].value_counts(normalize=True, dropna=False) * 100\n",
    "        df_output = pd.DataFrame({column: value_counts.index, \n",
    "                                  'Counts (% of total)': [f\"{count} ({percentage:.{decimal_places}f}%)\" for count, percentage in zip(value_counts.values, value_counts_percentages.values)]})\n",
    "        df_output[column] = df_output[column].fillna(\"Missing\")\n",
    "        df_output.set_index(column, inplace=True)\n",
    "        latex_table = df_output.to_latex(index=True, caption=caption or f\"Distribution of {column.replace('_', ' ').title()}\", label=label or f\"dist_{column}\")\n",
    "        print(latex_table)\n",
    "        print(self.generate_categorical_string(column, decimal_places))\n",
    "    \n",
    "    def generate_continuous_string(self, column, decimal_places):\n",
    "        mean_value = round(self.df[column].mean(), decimal_places)\n",
    "        std_dev = round(self.df[column].std(), decimal_places)\n",
    "        stats_string = f\"The mean {column} was {mean_value:.{decimal_places}f} (SD = {std_dev:.{decimal_places}f}).\"\n",
    "        return stats_string\n",
    "\n",
    "    def print_latex_table_continuous(self, columns, caption=None, label=None, decimal_places=2):\n",
    "        if not isinstance(columns, list):\n",
    "            columns = [columns]\n",
    "        stats_list = []\n",
    "        for column in columns:\n",
    "            mean_value = round(self.df[column].mean(), decimal_places)\n",
    "            median_value = round(self.df[column].median(), decimal_places)\n",
    "            std_dev = round(self.df[column].std(), decimal_places)\n",
    "            quartile_25 = round(np.percentile(self.df[column].dropna(), 25), decimal_places)\n",
    "            quartile_75 = round(np.percentile(self.df[column].dropna(), 75), decimal_places)\n",
    "            stats_series = pd.Series({'Mean': mean_value,\n",
    "                                      'Median': median_value,\n",
    "                                      'SD': std_dev,\n",
    "                                      '25th Percentile': quartile_25,\n",
    "                                      '75th Percentile': quartile_75},\n",
    "                                     name=column)\n",
    "            stats_list.append(stats_series)\n",
    "\n",
    "        df_output = pd.concat(stats_list, axis=1)\n",
    "        latex_table = df_output.T.to_latex(index=True, caption=caption or \"Distribution of Continuous Variables\", label=label)\n",
    "        print(latex_table)\n",
    "        for column in columns:\n",
    "            print(self.generate_continuous_string(column, decimal_places))\n",
    "\n",
    "ds = DescriptiveStats(df)\n",
    "dp = DescriptiveStats(df.drop_duplicates(subset=['participant_id']))\n",
    "\n",
    "dp.print_latex_table_continuous(['age', 'creativity_ai', 'creativity_human'], decimal_places=2, caption=\"Descriptive Stats\")\n",
    "\n",
    "dp.print_latex_table_categorical('gender', decimal_places=0)\n",
    "\n",
    "dp.print_latex_table_categorical('ai_feeling', decimal_places=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e57e614-04d1-4658-b7d6-148d58377b3c",
   "metadata": {},
   "source": [
    "# Race conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4101545-cb56-4fb0-ad48-06ac16b143f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d54294a-7c19-4a5c-9027-51b7442e1c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049bf0e3-86e1-4639-8129-8b4649f7c485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (misinformation_sim)",
   "language": "python",
   "name": "pycharm-9607488f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
