{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f6e9f8c-bf14-48df-b957-33b269c62658",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c145bf0-25b1-4b74-9c7a-afd45e516c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "key_path = f\"../../secrets/google_creds.json\"\n",
    "credentials = service_account.Credentials.from_service_account_file(key_path,\n",
    "                                                                    scopes=[\n",
    "                                                                        \"https://www.googleapis.com/auth/cloud-platform\"], )\n",
    "client = bigquery.Client(credentials=credentials, project=credentials.project_id)\n",
    "query = \"\"\"SELECT * FROM\n",
    "`net_expr.trials` AS t\n",
    "INNER JOIN `net_expr.person` as p\n",
    "ON t.participant_id = p.participant_id\n",
    "WHERE \n",
    "p.is_test is FALSE AND p.participant_id != 'seed' \n",
    "\"\"\"\n",
    "query_job = client.query(query)\n",
    "df = query_job.to_dataframe()\n",
    "\n",
    "# Two cases where a test response (response_text == \"Test\") was not flagged --> drop, note in paper\n",
    "er_ids = ['dbe96241-4d64-4ae6-bb6d-15e5e45b0760', 'e6fdd18f-de53-4159-965a-656aa75ba88d']\n",
    "df = df.query(\"response_id not in @er_ids\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbfca49-3eea-48b1-946d-1a23ae20c85e",
   "metadata": {},
   "source": [
    "## Data Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2dd4d7e-53c4-4d3b-971b-402cd52bfe7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Does every response id occur only once?\n",
      "YES: Every response id only occurs once\n",
      "\n",
      "TEST: Is it the case that all response texts have some words\n",
      "YES: All responses have some words\n"
     ]
    }
   ],
   "source": [
    "def verify_rid_unique():\n",
    "    print(\"TEST: Does every response id occur only once?\")\n",
    "    unique_rds = len(df['response_id'].unique())\n",
    "    all_rids = len(df['response_id'].tolist())\n",
    "    if all_rids == unique_rds:\n",
    "        print(\"YES: Every response id only occurs once\")\n",
    "    else:\n",
    "        print(\"NO: Some response ids occur twice\")\n",
    "    \n",
    "    \n",
    "def verify_no_response_blank():\n",
    "    print(\"TEST: Is it the case that all response texts have some words\")\n",
    "    blanks = len([x for x in df['response_id'].tolist() if x is None])\n",
    "    if blanks == 0:\n",
    "        print(\"YES: All responses have some words\")\n",
    "    else:\n",
    "        print(\"NO: Some responses don't have words\")\n",
    "    \n",
    "        \n",
    "verify_rid_unique()\n",
    "print()\n",
    "verify_no_response_blank()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a641a3c-b10b-4b67-b2f3-a59e9e5efd47",
   "metadata": {},
   "source": [
    "# Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c54bf98-6046-42cc-880a-0400f9490542",
   "metadata": {},
   "source": [
    "## Clean source column\n",
    "\n",
    "We tracked where traffic came from by appending different things to the request arguments for the experiment site. E.g: If posting the experiment on Facebook we would make the URL `experiment.com?from=facebook` so then `request_args` would be equal to `from=facebook`. But in some cases, no `request args` are available. This happens if somehow the request_args are stripped. There should be very few cases of this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8ebf96d-c8ff-4153-8dd9-d3f102f3cdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Does every source marked as OTHER have no request args?\n",
      "YES: For every source marked as `other`, we marked it as `other` because it does not have request args\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Creative Mornings newsletter    1439\n",
       "r/InternetIsBeautiful           1131\n",
       "r/samplesize                     390\n",
       "share                            251\n",
       "r/chatgpt                         79\n",
       "r/writing                         30\n",
       "other                             23\n",
       "r/poetry                          15\n",
       "facebook                           7\n",
       "Name: source, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def verify_other_source():\n",
    "    print(\"TEST: Does every source marked as OTHER have no request args?\")\n",
    "    other_request_args = df.query(\"source=='other'\")['request_args'].tolist()\n",
    "    len_other = len(other_request_args)\n",
    "    len_other_no_args = len([x for x in other_request_args if x == 'None'])\n",
    "    if len_other == len_other_no_args:\n",
    "        print(\"YES: For every source marked as `other`, we marked it as `other` because it does not have request args\")\n",
    "    else:\n",
    "        print(\"NO: We missed categorizing some sources\")\n",
    "    \n",
    "    \n",
    "\n",
    "def categorize_request_args(request_args):\n",
    "    request_args = request_args.lower()\n",
    "    if 'facebook' in request_args:\n",
    "        return 'facebook'\n",
    "    elif 'chatgpt' in request_args:\n",
    "        return 'r/chatgpt'\n",
    "    elif 'sample' in request_args:\n",
    "        return 'r/samplesize'\n",
    "    elif 'writing' in request_args:\n",
    "        return 'r/writing'\n",
    "    elif 'internet' in request_args:\n",
    "        return 'r/InternetIsBeautiful'\n",
    "    elif 'creative' in request_args:\n",
    "        return 'Creative Mornings newsletter'\n",
    "    elif 'poetry' in request_args:\n",
    "        return 'r/poetry'\n",
    "    elif 'results' in request_args or 'share' in request_args:\n",
    "        return 'share'\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "df['source'] = df['request_args'].apply(categorize_request_args)\n",
    "verify_other_source()\n",
    "\n",
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566eaefb-e82f-473b-92d7-de76941e9e80",
   "metadata": {},
   "source": [
    "## Clean Age Columns\n",
    "Participants entered their age, which was an int that had to be over 18. But let's make sure nobody entered anything weird -- and by weird we will look at responses over 70 years old. From inspecting the data, it appears that responses above 74 are troll responses -- relabel as NA and report in paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2debfeeb-fcff-4b91-8492-501391814f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    656.000000\n",
       "mean      36.859756\n",
       "std       29.071985\n",
       "min       18.000000\n",
       "25%       27.000000\n",
       "50%       34.000000\n",
       "75%       40.000000\n",
       "max      444.000000\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfp = df.drop_duplicates(subset=['participant_id'])\n",
    "dfp['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02fd50dd-75b9-4065-ae33-d628531c81d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>participant_id</th>\n",
       "      <th>response_text</th>\n",
       "      <th>response_date</th>\n",
       "      <th>condition</th>\n",
       "      <th>condition_order</th>\n",
       "      <th>item</th>\n",
       "      <th>world</th>\n",
       "      <th>init_array</th>\n",
       "      <th>ranked_array</th>\n",
       "      <th>...</th>\n",
       "      <th>country</th>\n",
       "      <th>age</th>\n",
       "      <th>is_test_1</th>\n",
       "      <th>referer</th>\n",
       "      <th>request_args</th>\n",
       "      <th>is_prolific_1</th>\n",
       "      <th>prolific_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>gender_describe</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>711</th>\n",
       "      <td>2e5141b6-814c-4e5f-89f6-9fe6155915e3</td>\n",
       "      <td>7f067979-5f4b-4729-a61f-827d82f929ff</td>\n",
       "      <td>Building a straw ball house</td>\n",
       "      <td>2023-07-14 03:00:50</td>\n",
       "      <td>f_u</td>\n",
       "      <td>0</td>\n",
       "      <td>tire</td>\n",
       "      <td>3</td>\n",
       "      <td>[723fd22b-6121-4935-82a1-54dfcecec5d9, e7726b1...</td>\n",
       "      <td>[a01068a1-ea4a-4c84-b9df-082ed1fe1b54, fd61a41...</td>\n",
       "      <td>...</td>\n",
       "      <td>United States</td>\n",
       "      <td>74</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>from=news&amp;sub=creative&amp;mc_cid=5c0a1bc1ef&amp;mc_ei...</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>prefer_self_describe</td>\n",
       "      <td>She/her/they</td>\n",
       "      <td>Creative Mornings newsletter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>5c366ee2-b272-454b-8f5f-b4b6e54e67b1</td>\n",
       "      <td>b2269ab4-bc4b-4049-b234-e240644e2cf7</td>\n",
       "      <td>to make into a bicycle tire made out of shoes</td>\n",
       "      <td>2023-07-08 17:26:18</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>shoe</td>\n",
       "      <td>3</td>\n",
       "      <td>[human_seed39_world3, human_seed37_world3, hum...</td>\n",
       "      <td>[human_seed38_world3, human_seed40_world3, hum...</td>\n",
       "      <td>...</td>\n",
       "      <td>China</td>\n",
       "      <td>420</td>\n",
       "      <td>False</td>\n",
       "      <td>https://createwithai.herokuapp.com/results/1b7...</td>\n",
       "      <td>how=results</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>prefer_not_disclose</td>\n",
       "      <td>None</td>\n",
       "      <td>share</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>d2d498ec-58a0-4286-bb03-e4aa50f0486a</td>\n",
       "      <td>4c7db1ec-9ae0-4b58-b4d3-8186d5599d90</td>\n",
       "      <td>Portable cell-phone</td>\n",
       "      <td>2023-07-08 15:21:19</td>\n",
       "      <td>f_l</td>\n",
       "      <td>0</td>\n",
       "      <td>shoe</td>\n",
       "      <td>1</td>\n",
       "      <td>[43d81087-73e7-41ba-949d-0041d1cd8811, f8ecf73...</td>\n",
       "      <td>[43d81087-73e7-41ba-949d-0041d1cd8811, f8ecf73...</td>\n",
       "      <td>...</td>\n",
       "      <td>Austria</td>\n",
       "      <td>432</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/</td>\n",
       "      <td>from=reddit&amp;sub=internet</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>man</td>\n",
       "      <td>None</td>\n",
       "      <td>r/InternetIsBeautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>4735ccd1-f9b8-4d39-a115-5ea58265e0a2</td>\n",
       "      <td>8459a1e8-f7a7-46b1-82a2-0d99056ac3f4</td>\n",
       "      <td>store krabby patty secret formula</td>\n",
       "      <td>2023-07-08 15:49:57</td>\n",
       "      <td>f_l</td>\n",
       "      <td>0</td>\n",
       "      <td>bottle</td>\n",
       "      <td>1</td>\n",
       "      <td>[d2a4126d-b581-4cb9-ba80-60dfc39d227b, 36b21de...</td>\n",
       "      <td>[d6829192-dce2-4a9d-9d46-e836acd74201, 36b21de...</td>\n",
       "      <td>...</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>444</td>\n",
       "      <td>False</td>\n",
       "      <td>https://www.reddit.com/</td>\n",
       "      <td>from=reddit&amp;sub=internet</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>prefer_not_disclose</td>\n",
       "      <td>None</td>\n",
       "      <td>r/InternetIsBeautiful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2939</th>\n",
       "      <td>cde0fcff-bf2b-45b7-bcd5-a32386664c8f</td>\n",
       "      <td>ae94364d-2fb8-47d0-b909-1c9e0d97aeff</td>\n",
       "      <td>Cut legs off to use as shorts</td>\n",
       "      <td>2023-07-08 15:05:43</td>\n",
       "      <td>m_l</td>\n",
       "      <td>0</td>\n",
       "      <td>pants</td>\n",
       "      <td>0</td>\n",
       "      <td>[ai_seed562, f28fb317-4ea6-418f-9040-dd180452c...</td>\n",
       "      <td>[ai_seed304, f28fb317-4ea6-418f-9040-dd180452c...</td>\n",
       "      <td>...</td>\n",
       "      <td>Canada</td>\n",
       "      <td>111</td>\n",
       "      <td>False</td>\n",
       "      <td>https://out.reddit.com/</td>\n",
       "      <td>from=reddit&amp;sub=internet</td>\n",
       "      <td>False</td>\n",
       "      <td>None</td>\n",
       "      <td>man</td>\n",
       "      <td>None</td>\n",
       "      <td>r/InternetIsBeautiful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               response_id  \\\n",
       "711   2e5141b6-814c-4e5f-89f6-9fe6155915e3   \n",
       "1859  5c366ee2-b272-454b-8f5f-b4b6e54e67b1   \n",
       "2013  d2d498ec-58a0-4286-bb03-e4aa50f0486a   \n",
       "2171  4735ccd1-f9b8-4d39-a115-5ea58265e0a2   \n",
       "2939  cde0fcff-bf2b-45b7-bcd5-a32386664c8f   \n",
       "\n",
       "                            participant_id  \\\n",
       "711   7f067979-5f4b-4729-a61f-827d82f929ff   \n",
       "1859  b2269ab4-bc4b-4049-b234-e240644e2cf7   \n",
       "2013  4c7db1ec-9ae0-4b58-b4d3-8186d5599d90   \n",
       "2171  8459a1e8-f7a7-46b1-82a2-0d99056ac3f4   \n",
       "2939  ae94364d-2fb8-47d0-b909-1c9e0d97aeff   \n",
       "\n",
       "                                      response_text       response_date  \\\n",
       "711                     Building a straw ball house 2023-07-14 03:00:50   \n",
       "1859  to make into a bicycle tire made out of shoes 2023-07-08 17:26:18   \n",
       "2013                            Portable cell-phone 2023-07-08 15:21:19   \n",
       "2171              store krabby patty secret formula 2023-07-08 15:49:57   \n",
       "2939                  Cut legs off to use as shorts 2023-07-08 15:05:43   \n",
       "\n",
       "     condition  condition_order    item  world  \\\n",
       "711        f_u                0    tire      3   \n",
       "1859         h                0    shoe      3   \n",
       "2013       f_l                0    shoe      1   \n",
       "2171       f_l                0  bottle      1   \n",
       "2939       m_l                0   pants      0   \n",
       "\n",
       "                                             init_array  \\\n",
       "711   [723fd22b-6121-4935-82a1-54dfcecec5d9, e7726b1...   \n",
       "1859  [human_seed39_world3, human_seed37_world3, hum...   \n",
       "2013  [43d81087-73e7-41ba-949d-0041d1cd8811, f8ecf73...   \n",
       "2171  [d2a4126d-b581-4cb9-ba80-60dfc39d227b, 36b21de...   \n",
       "2939  [ai_seed562, f28fb317-4ea6-418f-9040-dd180452c...   \n",
       "\n",
       "                                           ranked_array  ...        country  \\\n",
       "711   [a01068a1-ea4a-4c84-b9df-082ed1fe1b54, fd61a41...  ...  United States   \n",
       "1859  [human_seed38_world3, human_seed40_world3, hum...  ...          China   \n",
       "2013  [43d81087-73e7-41ba-949d-0041d1cd8811, f8ecf73...  ...        Austria   \n",
       "2171  [d6829192-dce2-4a9d-9d46-e836acd74201, 36b21de...  ...         Brazil   \n",
       "2939  [ai_seed304, f28fb317-4ea6-418f-9040-dd180452c...  ...         Canada   \n",
       "\n",
       "      age  is_test_1                                            referer  \\\n",
       "711    74      False                                               None   \n",
       "1859  420      False  https://createwithai.herokuapp.com/results/1b7...   \n",
       "2013  432      False                            https://www.reddit.com/   \n",
       "2171  444      False                            https://www.reddit.com/   \n",
       "2939  111      False                            https://out.reddit.com/   \n",
       "\n",
       "                                           request_args is_prolific_1  \\\n",
       "711   from=news&sub=creative&mc_cid=5c0a1bc1ef&mc_ei...         False   \n",
       "1859                                        how=results         False   \n",
       "2013                           from=reddit&sub=internet         False   \n",
       "2171                           from=reddit&sub=internet         False   \n",
       "2939                           from=reddit&sub=internet         False   \n",
       "\n",
       "      prolific_id                gender gender_describe  \\\n",
       "711          None  prefer_self_describe   She/her/they    \n",
       "1859         None   prefer_not_disclose            None   \n",
       "2013         None                   man            None   \n",
       "2171         None   prefer_not_disclose            None   \n",
       "2939         None                   man            None   \n",
       "\n",
       "                            source  \n",
       "711   Creative Mornings newsletter  \n",
       "1859                         share  \n",
       "2013         r/InternetIsBeautiful  \n",
       "2171         r/InternetIsBeautiful  \n",
       "2939         r/InternetIsBeautiful  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "over_seven = dfp[dfp['age']>=70]\n",
    "over_seven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ab40856-c4f2-4c68-bb24-1308d209c020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Users whose age we replaced with missing}\n",
      "\\begin{tabular}{llr}\n",
      "\\toprule\n",
      "{} &                        participant\\_id &  age \\\\\n",
      "\\midrule\n",
      "1859 &  b2269ab4-bc4b-4049-b234-e240644e2cf7 &  420 \\\\\n",
      "2013 &  4c7db1ec-9ae0-4b58-b4d3-8186d5599d90 &  432 \\\\\n",
      "2171 &  8459a1e8-f7a7-46b1-82a2-0d99056ac3f4 &  444 \\\\\n",
      "2939 &  ae94364d-2fb8-47d0-b909-1c9e0d97aeff &  111 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(dfp[dfp['age']>74][['participant_id', 'age']].to_latex(caption=\"Users whose age we replaced with missing\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "791eeca7-b990-43a6-b1e2-5015d7012000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_age(x):\n",
    "    if pd.isnull(x):  # Check for NaN values\n",
    "        return x\n",
    "    elif x <= 74:\n",
    "        return int(x)\n",
    "    else:\n",
    "        return np.NaN\n",
    "\n",
    "df['age'] = df['age'].apply(lambda x: fix_age(x))\n",
    "df['age'] = df['age'].astype('Int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9252230c-89a3-4ff5-b64d-e60c1e7ba282",
   "metadata": {},
   "source": [
    "# Clean columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ad9bdb-7a3d-4af2-bdb1-21825f3e8454",
   "metadata": {},
   "source": [
    "## Drop unused columns\n",
    "\n",
    "Note `is_troll` was not used; the relevant column is `is_profane`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d56c4988-cc51-4148-818d-b635939d9930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['response_id', 'participant_id', 'response_text', 'response_date',\n",
       "       'condition', 'condition_order', 'item', 'world', 'init_array',\n",
       "       'ranked_array', 'is_test', 'duration', 'is_troll', 'is_profane',\n",
       "       'is_prolific', 'participant_id_1', 'creativity_human', 'creativity_ai',\n",
       "       'dt', 'ai_feeling', 'country', 'age', 'is_test_1', 'referer',\n",
       "       'request_args', 'is_prolific_1', 'prolific_id', 'gender',\n",
       "       'gender_describe', 'source'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "823c0b0a-7949-4584-8c58-463ace7ef5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\"is_prolific\", \"is_prolific_1\", \"prolific_id\", \"is_test_1\", \"is_troll\", \"dt\", 'participant_id_1']\n",
    "for x in to_drop:\n",
    "    try:\n",
    "        df = df.drop(columns = [x], axis=0)\n",
    "    except KeyError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90222eda-36df-4018-b351-cc486a07b8b7",
   "metadata": {},
   "source": [
    "## Fix column types and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aec03417-e256-4f3e-b5c5-7163c8867dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['creativity_human'] = df['creativity_human'].astype('Int64')\n",
    "df['creativity_ai'] = pd.to_numeric(df['creativity_ai'], errors='coerce').astype('Int64')\n",
    "df = df.rename(columns={'world': 'response_chain'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b69302-4c4e-4cf0-81a0-c9984f804216",
   "metadata": {},
   "source": [
    "# Add trial_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32ef3be2-fc4d-41cc-ac7f-b42abb818248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['response_date'] = pd.to_datetime(df['response_date'])  # ensure response_date is datetime\n",
    "df['trial_no'] = df.groupby(['response_chain', 'condition', 'item'])['response_date'].rank(method='first').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cc761c-fcdb-4e72-bd01-a7a2e1b51482",
   "metadata": {},
   "source": [
    "## Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f88c4ce-efc6-48f6-a10a-a6e39a5820de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../../data/experiment_data/data_clean.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca6c24c0-50f5-4bb0-ba0c-4819c1b5202e",
   "metadata": {},
   "source": [
    "# Descriptive Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa2af55c-8dec-432e-a65e-702c553edef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "def make_aesthetic(hex_color_list=None):\n",
    "    \"\"\"Make Seaborn look clean\"\"\"\n",
    "    sns.set(style='white', context='poster', font_scale=0.8)\n",
    "    if not hex_color_list:\n",
    "        hex_color_list = [\n",
    "        \"#826AED\", # Medium slate blue\n",
    "        \"#00A896\", # Persian green\n",
    "        \"#D41876\", # Telemagenta\n",
    "        \"#89DAFF\", # Pale azure\n",
    "        \"#F7B2AD\", # Melon\n",
    "        \"#342E37\", # Dark grayish-purple\n",
    "        \"#7DCD85\", # Emerald\n",
    "        \"#E87461\", # Medium-bright orange\n",
    "        \"#E3B505\", # Saffron\n",
    "        \"#2C3531\", # Dark charcoal gray with a green undertone\n",
    "        \"#D4B2D8\", # Pink lavender\n",
    "        \"#7E6551\", # Coyote\n",
    "        \"#F45B69\", # Vibrant pinkish-red\n",
    "        \"#020887\", # Phthalo Blue\n",
    "        \"#F18805\"  # Tangerine\n",
    "        ]\n",
    "    sns.set_palette(sns.color_palette(hex_color_list))\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    plt.rcParams['axes.spines.right'] = False\n",
    "    plt.rcParams['axes.spines.top'] = False\n",
    "    plt.rcParams['axes.titlelocation'] = 'left'\n",
    "    plt.rcParams['axes.titleweight'] = 'bold'\n",
    "    plt.rcParams['axes.grid'] = True\n",
    "    plt.rcParams['grid.linestyle'] = '--'\n",
    "    plt.rcParams['grid.alpha'] = 0.5\n",
    "    plt.rcParams['axes.facecolor'] = 'white'\n",
    "    plt.rcParams['legend.frameon'] = True\n",
    "    plt.rcParams['legend.framealpha'] = 0.8\n",
    "    plt.rcParams['legend.facecolor'] = 'white'\n",
    "    plt.rcParams['savefig.transparent'] = True\n",
    "    plt.rcParams['savefig.bbox'] = 'tight'\n",
    "    plt.rcParams['savefig.pad_inches'] = 0.1\n",
    "    plt.rcParams['figure.autolayout'] = True\n",
    "make_aesthetic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b03449-0794-44ab-8b91-57642fc02a31",
   "metadata": {},
   "source": [
    "### Meta Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef12d38b-3f4e-43b3-a156-823d02b8cac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Summary Statistics of Experiment}\n",
      "\\label{overall_stats}\n",
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "{} &    Value \\\\\n",
      "\\midrule\n",
      "Unique Countries          &    48.00 \\\\\n",
      "Total Responses           &  3365.00 \\\\\n",
      "Unique Participants       &   822.00 \\\\\n",
      "Avg Responses/Participant &     4.09 \\\\\n",
      "Avg Duration/Response     &   144.80 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_new = pd.DataFrame(index=[\"Value\"])\n",
    "df_new['Unique Countries'] = [int(len(df['country'].unique()))]\n",
    "df_new['Total Responses'] = [int(len(df))]\n",
    "df_new['Unique Participants'] = [df['participant_id'].nunique()]\n",
    "df_new['Avg Responses/Participant'] = df_new['Total Responses'] / df_new['Unique Participants']\n",
    "df_new['Avg Duration/Response'] = [df['duration'].mean()]\n",
    "\n",
    "# Round the averages to two decimal places\n",
    "df_new['Avg Responses/Participant'] = df_new['Avg Responses/Participant'].round(2)\n",
    "df_new['Avg Duration/Response'] = df_new['Avg Duration/Response'].round(2)\n",
    "\n",
    "# Print as LaTeX table\n",
    "latex_table = df_new.T.to_latex(index=True, caption=\"Summary Statistics of Experiment\", label=\"overall_stats\")\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab3f133-bc92-4722-9a5a-047fae9b6c75",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b6f3d6a-63f1-47ec-92ed-b61a28bd59a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Sources of participants and trials}\n",
      "\\label{sources}\n",
      "\\begin{tabular}{lll}\n",
      "\\toprule\n",
      "{} & Participants (N, \\% of total) & Trials (N, \\% of total) \\\\\n",
      "\\midrule\n",
      "Creative Mornings newsletter &                  333 (40.5\\%) &           1439 (42.8\\%) \\\\\n",
      "r/InternetIsBeautiful        &                  298 (36.3\\%) &           1131 (33.6\\%) \\\\\n",
      "r/samplesize                 &                   93 (11.3\\%) &            390 (11.6\\%) \\\\\n",
      "share                        &                    61 (7.4\\%) &             251 (7.5\\%) \\\\\n",
      "r/chatgpt                    &                    19 (2.3\\%) &              79 (2.3\\%) \\\\\n",
      "r/writing                    &                     7 (0.9\\%) &              30 (0.9\\%) \\\\\n",
      "other                        &                     6 (0.7\\%) &              23 (0.7\\%) \\\\\n",
      "r/poetry                     &                     3 (0.4\\%) &              15 (0.4\\%) \\\\\n",
      "facebook                     &                     2 (0.2\\%) &               7 (0.2\\%) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "participants = df.groupby('source')['participant_id'].nunique()\n",
    "percentage_participants = (participants / df['participant_id'].nunique()) * 100\n",
    "trials = df['source'].value_counts()\n",
    "percentage_trials = (trials / df.shape[0]) * 100\n",
    "result = pd.DataFrame({\n",
    "    'Participants': participants,\n",
    "    'Percentage of Participants': percentage_participants,\n",
    "    'Trials': trials,\n",
    "    'Percentage of Trials': percentage_trials,\n",
    "})\n",
    "\n",
    "result = result.sort_values('Participants', ascending=False)\n",
    "result['Participants (N, % of total)'] = result['Participants'].astype(str) + ' (' + result['Percentage of Participants'].round(1).astype(str) + '%)'\n",
    "result['Trials (N, % of total)'] = result['Trials'].astype(str) + ' (' + result['Percentage of Trials'].round(1).astype(str) + '%)'\n",
    "result = result.drop(columns=['Participants', 'Percentage of Participants', 'Trials', 'Percentage of Trials'])\n",
    "latex_table = result.to_latex(caption=\"Sources of participants and trials\", label=\"sources\")\n",
    "\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08f0344d-9b9b-4d39-882b-2fadcf856cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Descriptive Stats}\n",
      "\\begin{tabular}{lrrrrr}\n",
      "\\toprule\n",
      "{} &   Mean &  Median &     SD &  25th Percentile &  75th Percentile \\\\\n",
      "\\midrule\n",
      "age              &  34.93 &    33.5 &  10.87 &             27.0 &            40.00 \\\\\n",
      "creativity\\_ai    &  58.04 &    60.0 &  26.54 &             40.0 &            76.25 \\\\\n",
      "creativity\\_human &  58.86 &    62.0 &  23.51 &             45.0 &            75.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "The mean age was 34.93 (SD = 10.87).\n",
      "The mean creativity_ai was 58.04 (SD = 26.54).\n",
      "The mean creativity_human was 58.86 (SD = 23.51).\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Distribution of Gender}\n",
      "\\label{dist_gender}\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "{} & Counts (\\% of total) \\\\\n",
      "gender               &                     \\\\\n",
      "\\midrule\n",
      "woman                &           296 (36\\%) \\\\\n",
      "man                  &           260 (32\\%) \\\\\n",
      "Missing              &           221 (27\\%) \\\\\n",
      "non-binary           &             22 (3\\%) \\\\\n",
      "prefer\\_not\\_disclose  &             16 (2\\%) \\\\\n",
      "prefer\\_self\\_describe &              7 (1\\%) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "Of the non-missing values, the sample was 49\\% woman, 43\\% man, 4\\% non-binary, 3\\% prefer_not_disclose, 1\\% prefer_self_describe. 27% of responses were missing.\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Distribution of Ai Feeling}\n",
      "\\label{dist_ai_feeling}\n",
      "\\begin{tabular}{ll}\n",
      "\\toprule\n",
      "{} & Counts (\\% of total) \\\\\n",
      "ai\\_feeling &                     \\\\\n",
      "\\midrule\n",
      "neutral    &           396 (48\\%) \\\\\n",
      "excited    &           222 (27\\%) \\\\\n",
      "concerned  &           193 (23\\%) \\\\\n",
      "Missing    &             11 (1\\%) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "Of the non-missing values, the sample was 49\\% neutral, 27\\% excited, 24\\% concerned. 1% of responses were missing.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class DescriptiveStats:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def generate_categorical_string(self, column, decimal_places):\n",
    "        percentages = self.df[column].value_counts(normalize=True, dropna=True) * 100\n",
    "        percentage_nan = self.df[column].isna().mean() * 100\n",
    "        percentage_string = \", \".join([f\"{percentage:.{decimal_places}f}\\% {index}\" for index, percentage in percentages.items()])\n",
    "        percentage_string += f\". {percentage_nan:.{decimal_places}f}% of responses were missing.\"\n",
    "        return f\"Of the non-missing values, the sample was {percentage_string}\"\n",
    "\n",
    "    def print_latex_table_categorical(self, column, caption=None, label=None, decimal_places=2):\n",
    "        value_counts = self.df[column].value_counts(dropna=False)\n",
    "        value_counts_percentages = self.df[column].value_counts(normalize=True, dropna=False) * 100\n",
    "        df_output = pd.DataFrame({column: value_counts.index, \n",
    "                                  'Counts (% of total)': [f\"{count} ({percentage:.{decimal_places}f}%)\" for count, percentage in zip(value_counts.values, value_counts_percentages.values)]})\n",
    "        df_output[column] = df_output[column].fillna(\"Missing\")\n",
    "        df_output.set_index(column, inplace=True)\n",
    "        latex_table = df_output.to_latex(index=True, caption=caption or f\"Distribution of {column.replace('_', ' ').title()}\", label=label or f\"dist_{column}\")\n",
    "        print(latex_table)\n",
    "        print(self.generate_categorical_string(column, decimal_places))\n",
    "    \n",
    "    def generate_continuous_string(self, column, decimal_places):\n",
    "        mean_value = round(self.df[column].mean(), decimal_places)\n",
    "        std_dev = round(self.df[column].std(), decimal_places)\n",
    "        stats_string = f\"The mean {column} was {mean_value:.{decimal_places}f} (SD = {std_dev:.{decimal_places}f}).\"\n",
    "        return stats_string\n",
    "\n",
    "    def print_latex_table_continuous(self, columns, caption=None, label=None, decimal_places=2):\n",
    "        if not isinstance(columns, list):\n",
    "            columns = [columns]\n",
    "        stats_list = []\n",
    "        for column in columns:\n",
    "            mean_value = round(self.df[column].mean(), decimal_places)\n",
    "            median_value = round(self.df[column].median(), decimal_places)\n",
    "            std_dev = round(self.df[column].std(), decimal_places)\n",
    "            quartile_25 = round(np.percentile(self.df[column].dropna(), 25), decimal_places)\n",
    "            quartile_75 = round(np.percentile(self.df[column].dropna(), 75), decimal_places)\n",
    "            stats_series = pd.Series({'Mean': mean_value,\n",
    "                                      'Median': median_value,\n",
    "                                      'SD': std_dev,\n",
    "                                      '25th Percentile': quartile_25,\n",
    "                                      '75th Percentile': quartile_75},\n",
    "                                     name=column)\n",
    "            stats_list.append(stats_series)\n",
    "\n",
    "        df_output = pd.concat(stats_list, axis=1)\n",
    "        latex_table = df_output.T.to_latex(index=True, caption=caption or \"Distribution of Continuous Variables\", label=label)\n",
    "        print(latex_table)\n",
    "        for column in columns:\n",
    "            print(self.generate_continuous_string(column, decimal_places))\n",
    "\n",
    "ds = DescriptiveStats(df)\n",
    "dp = DescriptiveStats(df.drop_duplicates(subset=['participant_id']))\n",
    "\n",
    "dp.print_latex_table_continuous(['age', 'creativity_ai', 'creativity_human'], decimal_places=2, caption=\"Descriptive Stats\")\n",
    "\n",
    "dp.print_latex_table_categorical('gender', decimal_places=0)\n",
    "\n",
    "dp.print_latex_table_categorical('ai_feeling', decimal_places=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (misinformation_sim)",
   "language": "python",
   "name": "pycharm-9607488f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
